import streamlit as st
import os
from transformers import AutoTokenizer
import base64
from forms.contact import cadastro_pedido
import asyncio

import replicate
from langchain.llms import Replicate

import smtplib
from email.mime.multipart import MIMEMultipart
from email.mime.text import MIMEText
from decouple import config


st.set_page_config(page_title='ORACULO MODAS', page_icon="üëó", layout="wide")


# --- Verifica se o token da API est√° nos segredos ---
if 'REPLICATE_API_TOKEN':
    replicate_api = config('REPLICATE_API_TOKEN')
else:
    # Se a chave n√£o est√° nos segredos, define um valor padr√£o ou continua sem o token
    replicate_api = None

# Essa parte ser√° executada se voc√™ precisar do token em algum lugar do seu c√≥digo
if replicate_api is None:
    # Se voc√™ quiser fazer algo espec√≠fico quando n√£o h√° token, voc√™ pode gerenciar isso aqui
    # Por exemplo, configurar uma l√≥gica padr√£o ou deixar o aplicativo continuar sem mostrar nenhuma mensagem:
    st.warning('Um token de API √© necess√°rio para determinados recursos.', icon='‚ö†Ô∏è')

# Inicializar o modelo da Replicate
llm = Replicate(
    model="meta/meta-llama-3-70b-instruct",
    api_token=replicate_api
)



async def showPedido():

    system_prompt = f'''
    Voc√™ √© uma atendente virtual chamada "KIRA", que atuar√° como atendente virtual da plataforma FAM, facilitando a intera√ß√£o entre fabricantes de moda e lojistas no Brasil. 
    
    1. **Defini√ß√£o Clara**: Voc√™ deve ser uma assistente que n√£o apenas responde perguntas, mas tamb√©m oferece conselhos sobre como maximizar as vendas, sugere estrat√©gias de marketing e conecta os fabricantes aos lojistas de forma eficaz. Isso ajudar√° a IA a entender melhor as expectativas dos usu√°rios.
    
    2. **Estrutura da Resposta**: Ao interagir com os usu√°rios, KIRA deve organizar suas respostas em partes l√≥gicas. Por exemplo:
    - **Sauda√ß√£o**: "Ol√°! Sou a KIRA, sua assistente virtual."
    - **Identifica√ß√£o de Necessidades**: "Como posso ajudar voc√™ hoje? Est√° buscando conectar-se a um lojista ou precisa de dicas para aumentar suas vendas?"
    - **Solu√ß√£o**: Ap√≥s a identifica√ß√£o, KIRA pode fornecer informa√ß√µes espec√≠ficas ou direcionar o usu√°rio para as funcionalidades da plataforma.
    
    3. **Tom de Comunica√ß√£o**: O tom de seu deve ser amig√°vel e acess√≠vel. Em conversas mais formais, ela pode usar uma linguagem t√©cnica e objetiva, mas em intera√ß√µes cotidianas, ela deve adotar um tom mais descontra√≠do e motivacional. Por exemplo: "Vamos juntos fazer seu neg√≥cio brilhar no mercado!".
    
    4. **Personaliza√ß√£o e Precis√£o**:Voc√™ deve ser capaz de personalizar suas respostas com base nas informa√ß√µes fornecidas pelos usu√°rios. Por exemplo, se o fabricante mencionar que est√° lan√ßando uma nova linha de produtos, FAMOSA pode oferecer dicas espec√≠ficas sobre como promov√™-los para os lojistas, aumentando assim a relev√¢ncia da intera√ß√£o.
    5. Se o cliente quiser fazer uma assinatura para ter acessoa plataforma envie este link: https://buy.stripe.com/test_fZeg2L7MBcCE9heeUY
    6. Se o cliente desejar conversar com uma consultora envie este link de WhatsApp da Consultora Mari: https://wa.me/+553199302907
    '''

    # Set assistant icon to Snowflake logo
    icons = {"assistant": "./src/img/perfil-kira1.png", "user": "./src/img/perfil-usuario.png"}

    # Replicate Credentials
    with st.sidebar:
        st.markdown(
            """
            <h1 style='text-align: center;'>KIRA - Assistente Virtual FAM</h1>
            """,
            unsafe_allow_html=True
        )

        st.markdown(
            """
            <style>
            .cover-glow {
                width: 100%;
                height: auto;
                padding: 3px;
                box-shadow: 
                    0 0 5px #330000,
                    0 0 10px #660000,
                    0 0 15px #990000,
                    0 0 20px #CC0000,
                    0 0 25px #FF0000,
                    0 0 30px #FF3333,
                    0 0 35px #FF6666;
                position: relative;
                z-index: -1;
                border-radius: 30px;  /* Rounded corners */
            }
            </style>
            """,
            unsafe_allow_html=True,
        )

        # Function to convert image to base64
        def img_to_base64(image_path):
            with open(image_path, "rb") as img_file:
                return base64.b64encode(img_file.read()).decode()

        # Load and display sidebar image with glowing effect
        img_path = "./src/img/perfil-kira.jpeg"
        img_base64 = img_to_base64(img_path)
        st.sidebar.markdown(
            f'<img src="data:image/png;base64,{img_base64}" class="cover-glow">',
            unsafe_allow_html=True,
        )
        st.sidebar.markdown("---")
        st.info("Agora que voc√™ est√° aqui, vamos aprender como interagir comigo, KIRA, sua assistente virtual de moda!"
    
                "Perguntando √† KIRA"
                
                "Para perguntar algo, basta digitar sua pergunta no campo de texto abaixo." "Voc√™ pode perguntar sobre:"
                
                "Produtos e marcas dispon√≠veis na plataforma"
                "Tend√™ncias e estilos de moda"
                "Dicas de compra e estilo"
                "Informa√ß√µes sobre os fornecedores e lojas parceiras"
                
                "Exemplos de Perguntas"
                
                "Quais s√£o as √∫ltimas tend√™ncias de moda para o ver√£o?"
                "Onde posso encontrar um vestido de noite para uma ocasi√£o especial?"
                "Quais s√£o as melhores marcas de cal√ßados para homens?"
                
                "Interagindo com a KIRA"
                
                "Al√©m de perguntar, voc√™ tamb√©m pode interagir comigo de outras maneiras:"
                
                "Clique nos bot√µes de op√ß√£o para escolher entre diferentes respostas"
                "Use os √≠cones de emo√ß√£o para expressar sua opini√£o ou humor"
                "Compartilhe suas prefer√™ncias e interesses para que eu possa oferecer recomenda√ß√µes personalizadas"
                
                "Dicas e Lembran√ßas"
                
                "Certifique-se de digitar sua pergunta de forma clara e concisa"
                "Se voc√™ n√£o encontrar a resposta que procura, n√£o hesite em perguntar novamente"
                "Lembre-se de que estou aqui para ajud√°-lo, ent√£o n√£o hesite em me perguntar qualquer coisa!"
                
                "Se voc√™ desejar finalizar uma compra aguarde para que eu mande o link de pagamento da compra."
                "Aqui est√° o link para efetuar seu pagamento: https://buy.stripe.com/test_fZeg2L7MBcCE9heeUY"
                "Se voce quiser conversar com uma de nossas consultoras entre em contato com a Mari clicando no link: https://wa.me/+553199302907 ")


        st.sidebar.markdown("---")


    # Store LLM-generated responses
    if "messages" not in st.session_state.keys():
        st.session_state.messages = [{"role": "assistant", "content": 'Ol√°! Sou a KIRA, sua assistente virtual de moda aqui na FAM. Vou te ajudar a conectar com os melhores fabricantes e tornar sua experi√™ncia de compra ainda mais incr√≠vel.'}]

    # Display or clear chat messages
    for message in st.session_state.messages:
        with st.chat_message(message["role"], avatar=icons[message["role"]]):
            st.write(message["content"])

    def clear_chat_history():
        st.session_state.messages = [{"role": "assistant", "content": 'Ol√°! Sou a KIRA, sua assistente virtual de moda aqui na FAM. Vou te ajudar a conectar com os melhores fabricantes e tornar sua experi√™ncia de compra ainda mais incr√≠vel.'}]

    st.sidebar.button('LIMPAR CONVERSA', on_click=clear_chat_history)
    st.sidebar.caption(
        'Built by [Snowflake](https://snowflake.com/) to demonstrate [Snowflake Arctic](https://www.snowflake.com/blog/arctic-open-and-efficient-foundation-language-models-snowflake). App hosted on [Streamlit Community Cloud](https://streamlit.io/cloud). Model hosted by [Replicate](https://replicate.com/snowflake/snowflake-arctic-instruct).')
    st.sidebar.caption(
        'Build your own app powered by Arctic and [enter to win](https://arctic-streamlit-hackathon.devpost.com/) $10k in prizes.')

    st.sidebar.markdown("Desenvolvido por [WILLIAM EUST√ÅQUIO](https://www.instagram.com/flashdigital.tech/)")

    @st.cache_resource(show_spinner=False)
    def get_tokenizer():
        """Get a tokenizer to make sure we're not sending too much text
        text to the Model. Eventually we will replace this with ArcticTokenizer
        """
        return AutoTokenizer.from_pretrained("huggyllama/llama-7b")

    def get_num_tokens(prompt):
        """Get the number of tokens in a given prompt"""
        tokenizer = get_tokenizer()
        tokens = tokenizer.tokenize(prompt)
        return len(tokens)

    # Function for generating Snowflake Arctic response

    def generate_arctic_response():
        prompt = []
        for dict_message in st.session_state.messages:

            if dict_message["role"] == "user":
                prompt.append("<|im_start|>user\n" + dict_message["content"] + "<|im_end|>")
            else:
                prompt.append("<|im_start|>assistant\n" + dict_message["content"] + "<|im_end|>")

        prompt.append("<|im_start|>assistant")
        prompt.append("")
        prompt_str = "\n".join(prompt)

        if get_num_tokens(prompt_str) >= 3500:  # padr√£o3072
            if cadastro_pedido in system_prompt:
                @st.dialog("DADOS PARA PEDIDO")
                def show_contact_form():
                    cadastro_pedido()

        for event in replicate.stream(
                "meta/meta-llama-3-70b-instruct",
                input={
                    "top_k": 0,
                    "top_p": 1,
                    "prompt": prompt_str,
                    "temperature": 0.1,
                    "system_prompt": system_prompt,
                    "length_penalty": 1,
                    "max_new_tokens": 3500,

                },
        ):
            yield str(event)

    # User-provided prompt
    if prompt := st.chat_input(disabled=not replicate_api):
        st.session_state.messages.append({"role": "user", "content": prompt})
        with st.chat_message("user", avatar="./src/img/perfil-usuario.png"):
            st.write(prompt)

    # Generate a new response if last message is not from assistant
    if st.session_state.messages[-1]["role"] != "assistant":
        with st.chat_message("assistant", avatar="./src/img/perfil-kira1.png"):
            response = generate_arctic_response()
            full_response = st.write_stream(response)
        message = {"role": "assistant", "content": full_response}
        st.session_state.messages.append(message)



